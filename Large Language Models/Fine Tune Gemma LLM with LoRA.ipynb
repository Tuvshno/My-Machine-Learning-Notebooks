{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"competition","sourceId":64148,"databundleVersionId":7669720},{"sourceType":"datasetVersion","sourceId":7711309,"datasetId":4484051,"databundleVersionId":7810193},{"sourceType":"modelInstanceVersion","sourceId":11371,"databundleVersionId":7771674,"modelInstanceId":5171}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook will initially go through the [Kaggle QA with Gemma - KerasNLP Starter](https://www.kaggle.com/code/awsaf49/kaggle-qa-with-gemma-kerasnlp-starter) notebook and build upon it.","metadata":{}},{"cell_type":"markdown","source":"## Install Libraries","metadata":{}},{"cell_type":"code","source":"!pip install -q -U keras-nlp\n!pip install -q -U keras>=3","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:30:34.952000Z","iopub.execute_input":"2024-04-01T08:30:34.952864Z","iopub.status.idle":"2024-04-01T08:31:04.767844Z","shell.execute_reply.started":"2024-04-01T08:30:34.952827Z","shell.execute_reply":"2024-04-01T08:31:04.766870Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\n\nimport keras\nimport keras_nlp\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\ntqdm.pandas() # progress bar for pandas\n\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom IPython.display import display, Markdown","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:31:08.368624Z","iopub.execute_input":"2024-04-01T08:31:08.368984Z","iopub.status.idle":"2024-04-01T08:31:22.812366Z","shell.execute_reply.started":"2024-04-01T08:31:08.368954Z","shell.execute_reply":"2024-04-01T08:31:22.811432Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-04-01 08:31:12.970729: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-01 08:31:12.970873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-01 08:31:13.111497: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    dataset_path = \"/kaggle/input/kaggle-docs/questions_answers\"\n    preset = \"gemma_2b_en\" # Pretrained model\n    sequence_length = 512 # max size of the input for training\n    batch_size = 1 # size of the input batch in training\n    epochs = 10 # number of epochs to train","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:31:32.855127Z","iopub.execute_input":"2024-04-01T08:31:32.855496Z","iopub.status.idle":"2024-04-01T08:31:32.860325Z","shell.execute_reply.started":"2024-04-01T08:31:32.855468Z","shell.execute_reply":"2024-04-01T08:31:32.859393Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Reproducibility","metadata":{}},{"cell_type":"code","source":"keras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:31:35.976502Z","iopub.execute_input":"2024-04-01T08:31:35.976845Z","iopub.status.idle":"2024-04-01T08:31:35.981483Z","shell.execute_reply.started":"2024-04-01T08:31:35.976818Z","shell.execute_reply":"2024-04-01T08:31:35.980506Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Data\nThe data is provided from a dataset called **Kaggle Docs** which contains around 60 question-answer pairs from raw data from the `kaggle.com/docs` website. \n\n**To Do**\n\nLater, we will augument the data more so we can have more samples to work with.\n\n**Data Format**\n- The question-answer paid is stored in `./kaggle-docs/questions_answers/data.csv` file.\n- This file includes:\n    - `Question`: A question about the Kaggle Platform\n    - `Answer`: Answer to the question in Markdown Format.\n    - `Category`: The category of the question.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(f\"{CFG.dataset_path}/data.csv\")\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:31:39.608831Z","iopub.execute_input":"2024-04-01T08:31:39.609653Z","iopub.status.idle":"2024-04-01T08:31:39.641977Z","shell.execute_reply.started":"2024-04-01T08:31:39.609621Z","shell.execute_reply":"2024-04-01T08:31:39.641095Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                            Question  \\\n0  What are the different types of competitions a...   \n1  What are the different competition formats on ...   \n\n                                              Answer     Category  \n0  # Types of Competitions\\n\\nKaggle Competitions...  competition  \n1  There are handful of different formats competi...  competition  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are the different types of competitions a...</td>\n      <td># Types of Competitions\\n\\nKaggle Competitions...</td>\n      <td>competition</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What are the different competition formats on ...</td>\n      <td>There are handful of different formats competi...</td>\n      <td>competition</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This will be the template used:\n```\nCategory: ...\n\nQuestion: ...\n\nAnswer: ...\n```\n\n**To Do** \n\nTry better prompt engineering techniques.","metadata":{}},{"cell_type":"code","source":"template = \"\\n\\nCategory:\\nkaggle-{Category}\\n\\nQuestion:\\n{Question}\\n\\nAnswer:\\n{Answer}\"","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:31:46.414057Z","iopub.execute_input":"2024-04-01T08:31:46.414384Z","iopub.status.idle":"2024-04-01T08:31:46.418622Z","shell.execute_reply.started":"2024-04-01T08:31:46.414358Z","shell.execute_reply":"2024-04-01T08:31:46.417620Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df[\"prompt\"] = df.progress_apply(lambda row: template.format(Category=row.Category,\n                                                             Question=row.Question,\n                                                             Answer=row.Answer), axis=1)\ndata = df.prompt.tolist() # Converts the column into a list","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:31:47.930665Z","iopub.execute_input":"2024-04-01T08:31:47.931401Z","iopub.status.idle":"2024-04-01T08:31:47.958945Z","shell.execute_reply.started":"2024-04-01T08:31:47.931366Z","shell.execute_reply":"2024-04-01T08:31:47.958069Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/60 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e687172fbbee433faeae6720c9214ad5"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Sample\n\nLet's examine a sample prompt. Since the answers in the dataset are in markdown format, we should render also in markdown.","metadata":{}},{"cell_type":"code","source":"def colorize_text(text):\n    for word, color in zip([\"Category\", \"Question\", \"Answer\"], [\"blue\", \"red\", \"green\"]):\n         text = text.replace(f\"\\n\\n{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:31:49.900291Z","iopub.execute_input":"2024-04-01T08:31:49.900619Z","iopub.status.idle":"2024-04-01T08:31:49.905792Z","shell.execute_reply.started":"2024-04-01T08:31:49.900593Z","shell.execute_reply":"2024-04-01T08:31:49.904888Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# take a random sample\nsample = data[45]\n\n# give colors to the question, answer, and category\nsample = colorize_text(sample)\n\n# Show sample\ndisplay(Markdown(sample))","metadata":{"execution":{"iopub.status.busy":"2024-04-01T07:49:53.271501Z","iopub.execute_input":"2024-04-01T07:49:53.271955Z","iopub.status.idle":"2024-04-01T07:49:53.280660Z","shell.execute_reply.started":"2024-04-01T07:49:53.271922Z","shell.execute_reply":"2024-04-01T07:49:53.279408Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='blue'>Category:</font>**\nkaggle-competition-setup\n\n**<font color='red'>Question:</font>**\nHow do Kaggle competitions work?\n\n**<font color='green'>Answer:</font>**\n## Overview\n\nEvery competition has two things:\n\na) a clearly defined problem that participants need to solve using a machine learning model\nb) a dataset that’s used both for training and evaluating the effectiveness of these models.\n\nFor example, in the [Store Sales – Time Series Forecasting](https://www.kaggle.com/competitions/store-sales-time-series-forecasting) competition, participants must accurately predict how many of each grocery item will sell using a dataset of past product and sales information from a grocery retailer.\n\nOnce the competition starts, participants can submit their predictions. Kaggle will score them for accuracy, and the team will be placed on a ranked leaderboard. The team at the top of the leaderboard at the deadline wins!\n\n## Datasets, Submissions & Leaderboards\n\nEvery competition’s dataset is split into two smaller datasets.\n\n- One of these smaller datasets will be given to participants to train their models, typically named `train.csv`.\n- The other dataset will be mostly hidden from participants and used by Kaggle for testing and scoring, named `test.csv` and `solution.csv` (`test.csv` is the same as `solution.csv` except that `test.csv` contains the feature values and `solution.csv` contains the ground truth variable(s) – participants will never, ever see `solution.csv`).\n\nWhen a participant feels ready to make a submission to the competition, they will use `test.csv` to generate a prediction and upload a CSV file. Kaggle will automatically score the submission for accuracy using the hidden `solution.csv` file.\n\nMost competitions have a maximum number of submissions that a participant can make each day and a final deadline at which point the leaderboard will be frozen.\n\nIt’s conceivable that a participant could use the mechanics of a Kaggle competition to overfit a solution - which would be great for winning a competition, but not valuable for a real-world application.\n\nTo help prevent this, Kaggle has two leaderboards – the public and private leaderboard. The competition host splits the `solution.csv` dataset into two parts, using one part for the public leaderboard and another part for the private leaderboard. Participants generally will now know which samples are public vs private. The private leaderboard is kept a secret until after the competition deadline and is used as the official leaderboard for determining the final ranking."},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Analysis\n\nLets see how many question-answer pairs we have per category.","metadata":{}},{"cell_type":"code","source":"unique_labels, label_counts = np.unique(df.Category.tolist(), return_counts=True)\n\n# Plotting\nfig = go.Figure(data=go.Bar(x=unique_labels, y=label_counts))\nfig.update_layout(\n    title=\"Category Distribution\",\n    xaxis_title=\"Category\",\n    yaxis_title=\"Count\",\n)\n\nfig.update_traces(text=label_counts, textposition=\"outside\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:31:57.886889Z","iopub.execute_input":"2024-04-01T08:31:57.887273Z","iopub.status.idle":"2024-04-01T08:31:58.149056Z","shell.execute_reply.started":"2024-04-01T08:31:57.887241Z","shell.execute_reply":"2024-04-01T08:31:58.148180Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"8a0967ae-7329-4ce1-91c1-58d29da9ab16\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8a0967ae-7329-4ce1-91c1-58d29da9ab16\")) {                    Plotly.newPlot(                        \"8a0967ae-7329-4ce1-91c1-58d29da9ab16\",                        [{\"x\":[\"api\",\"competition\",\"competition-setup\",\"dataset\",\"gpu\",\"model\",\"noteboook\",\"organization\",\"tpu\"],\"y\":[4,8,10,6,1,6,11,5,9],\"type\":\"bar\",\"text\":[4.0,8.0,10.0,6.0,1.0,6.0,11.0,5.0,9.0],\"textposition\":\"outside\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Category Distribution\"},\"xaxis\":{\"title\":{\"text\":\"Category\"}},\"yaxis\":{\"title\":{\"text\":\"Count\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('8a0967ae-7329-4ce1-91c1-58d29da9ab16');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This means that Categories with less question and answers are most likely going to have the weakest responses. Therefore, we should do some auguementation or dive deeper into the dataset for more data.","metadata":{}},{"cell_type":"markdown","source":"We are going to utilize the Gemma Casual Language model which predicts the next token based on the previous tokens. This task setup can be used to train the model unsupervised on plain text input, which is what we are using it for. It can also autoregressively generate plain text similar to the data used for training which is what we want for this problem. We can also pre-train or fine tune the model by calling `fit()`.\n\nThe model has a `generate()` method which can generate text based on a prompt. You can have additional control on its generation strategy by controlling the sampler on compile. ","metadata":{}},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:32:01.746510Z","iopub.execute_input":"2024-04-01T08:32:01.746878Z","iopub.status.idle":"2024-04-01T08:33:05.508167Z","shell.execute_reply.started":"2024-04-01T08:32:01.746849Z","shell.execute_reply":"2024-04-01T08:33:05.507274Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"x, y, sample_weight = gemma_lm.preprocessor(data[0:2])","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:34:18.832229Z","iopub.execute_input":"2024-04-01T08:34:18.832608Z","iopub.status.idle":"2024-04-01T08:34:19.175784Z","shell.execute_reply.started":"2024-04-01T08:34:18.832579Z","shell.execute_reply":"2024-04-01T08:34:19.175015Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"The preprocessing layer will take in batches of strings, and return outputs in a `(x,y, sample_weight)` format, wher e`y` is the next token id in the `x` sequence.\n\nAfter the preprocessor the data shape is `(num_samples, sequence_length)`.","metadata":{}},{"cell_type":"code","source":"for k, v in x.items():\n    print(k, \":\", v.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:34:21.252447Z","iopub.execute_input":"2024-04-01T08:34:21.253243Z","iopub.status.idle":"2024-04-01T08:34:21.258067Z","shell.execute_reply.started":"2024-04-01T08:34:21.253200Z","shell.execute_reply":"2024-04-01T08:34:21.257171Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"token_ids : (2, 8192)\npadding_mask : (2, 8192)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference before fine tuning","metadata":{}},{"cell_type":"code","source":"# Take on sample\nrow = df.iloc[2]\n\n# Generate prompt using template\nprompt = template.format(\n    Category=row.Category,\n    Question=row.Question,\n    Answer=\"\"\n)\n\n# Infer\noutput = gemma_lm.generate(prompt, max_length=256)\n\n# Colorize\noutput = colorize_text(output)\n\n# display \ndisplay(Markdown(output))","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:08:18.771140Z","iopub.execute_input":"2024-04-01T08:08:18.771575Z","iopub.status.idle":"2024-04-01T08:16:07.999425Z","shell.execute_reply.started":"2024-04-01T08:08:18.771549Z","shell.execute_reply":"2024-04-01T08:16:07.998407Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='blue'>Category:</font>**\nkaggle-competition\n\n**<font color='red'>Question:</font>**\nHow to join a competition?\n\n**<font color='green'>Answer:</font>**\n1. Go to the competition page.\n2. Click on the \"Join\" button.\n3. Enter your email address and click on the \"Join\" button.\n4. You will receive an email with a link to confirm your email address.\n5. Click on the link in the email to confirm your email address.\n6. You will now be able to log in to the competition.\n\n**<font color='blue'>Category:</font>**\nkaggle-competition\n\n**<font color='red'>Question:</font>**\nHow to submit a solution?\n\n**<font color='green'>Answer:</font>**\n1. Go to the competition page.\n2. Click on the \"Submit\" button.\n3. Enter your solution in the text box and click on the \"Submit\" button.\n4. You will receive a confirmation email with the status of your submission.\n\n**<font color='blue'>Category:</font>**\nkaggle-competition\n\n**<font color='red'>Question:</font>**\nHow to view the leaderboard?\n\n**<font color='green'>Answer:</font>**\n1. Go to the competition page.\n2. Click on the \"Leaderboard\" button.\n3. You will see the leaderboard with the top 100 participants.\n\n**<font color='blue'>Category:</font>**\nkaggle-competition\n\n**<font color='red'>Question:</font>**\nHow to view the"},"metadata":{}}]},{"cell_type":"markdown","source":"# Fine-tuning with LoRA\n\nIn order to get better responses, we will fine-tune the model with Low Rank Adaption (LoRA) on the dataset.\n\nIn a LLM, there is a dense layer of weights known as the pre-trained dense layer, which consists of a **d X d** weight matrix. These are the pretained weights of the model that were trained when the LLM was originally trained. LoRA are extra weights added to the LLM in order to fine tune the model, without ever touching the original pre-trained weights. This is known as freezing the pre-trained weights. When a LLM is originally getting an output it is calculated by the **W_0 * x + b_0** where W_0 is the weight matrix and x is the input and b_0 is the bias. \n\nLoRAs are initalized as two layers **A** and **B** and have the weights **d x r** and **r x d**. Here the **r** is known as the rank and allows how many trainable parameters are initialized for the LoRA. \n\nWhen we add the LoRA to the LLM, we change the equation for the output to **output = (W_0 * x + b_0) + (B * A * x)**.\n\nLoRA are initalized with A having the normal distribution of 0 and a variance of sigmia squared and B with 0.\n\n**But why does it save memory?**\n\nThe reason is because we only have trainable parameters **d x r** and **r x d** from the LoRA rather than the entire LLM pretrained weights. So, even though we are adding more parameters to the LLM we are only training a small subset of parameters.","metadata":{}},{"cell_type":"code","source":"# Enable LoRA for the model and set to rank 4\ngemma_lm.backbone.enable_lora(rank=4)\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:34:26.482345Z","iopub.execute_input":"2024-04-01T08:34:26.482791Z","iopub.status.idle":"2024-04-01T08:34:26.990229Z","shell.execute_reply.started":"2024-04-01T08:34:26.482759Z","shell.execute_reply":"2024-04-01T08:34:26.989361Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Notice how the trainable parameters went from 2,507,536,384 to 1,363,968.","metadata":{}},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Limit the input sequence length to 512 to control memory usage\ngemma_lm.preprocessor.sequence_length = CFG.sequence_length\n\n# Compile the model with loss, optimizer, and metric\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(learning_rate=8e-5),\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\n# Train Model\ngemma_lm.fit(data, epochs=CFG.epochs, batch_size=CFG.batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:34:29.553547Z","iopub.execute_input":"2024-04-01T08:34:29.554248Z","iopub.status.idle":"2024-04-01T08:42:49.030560Z","shell.execute_reply.started":"2024-04-01T08:34:29.554206Z","shell.execute_reply":"2024-04-01T08:42:49.029577Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 734ms/step - loss: 1.7209 - sparse_categorical_accuracy: 0.5241\nEpoch 2/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - loss: 1.6869 - sparse_categorical_accuracy: 0.5313\nEpoch 3/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 728ms/step - loss: 1.6175 - sparse_categorical_accuracy: 0.5417\nEpoch 4/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 728ms/step - loss: 1.5770 - sparse_categorical_accuracy: 0.5509\nEpoch 5/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 728ms/step - loss: 1.5537 - sparse_categorical_accuracy: 0.5552\nEpoch 6/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 727ms/step - loss: 1.5304 - sparse_categorical_accuracy: 0.5568\nEpoch 7/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 727ms/step - loss: 1.5028 - sparse_categorical_accuracy: 0.5630\nEpoch 8/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 727ms/step - loss: 1.4733 - sparse_categorical_accuracy: 0.5682\nEpoch 9/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 728ms/step - loss: 1.4444 - sparse_categorical_accuracy: 0.5747\nEpoch 10/10\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 728ms/step - loss: 1.4025 - sparse_categorical_accuracy: 0.5873\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x78e474589ed0>"},"metadata":{}}]},{"cell_type":"code","source":"gemma_lm.save('model.keras')","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:43:53.226981Z","iopub.execute_input":"2024-04-01T08:43:53.227377Z","iopub.status.idle":"2024-04-01T08:44:57.556943Z","shell.execute_reply.started":"2024-04-01T08:43:53.227344Z","shell.execute_reply":"2024-04-01T08:44:57.556091Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Inference after fine-tuning","metadata":{}},{"cell_type":"code","source":"# Take one sample\nrow = df.iloc[2]\n\n# Generate Prompt using template\nprompt = template.format(\n    Category=row.Category,\n    Question=row.Question,\n    Answer=\"\"\n)\n\n# Infer\noutput = gemma_lm.generate(prompt, max_length=256)\n\n# Colorize\noutput = colorize_text(output)\n\n# Display in markdown\ndisplay(Markdown(output))","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:45:52.166063Z","iopub.execute_input":"2024-04-01T08:45:52.166447Z","iopub.status.idle":"2024-04-01T08:46:06.486166Z","shell.execute_reply.started":"2024-04-01T08:45:52.166418Z","shell.execute_reply":"2024-04-01T08:46:06.485216Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='blue'>Category:</font>**\nkaggle-competition\n\n**<font color='red'>Question:</font>**\nHow to join a competition?\n\n**<font color='green'>Answer:</font>**\nYou can view and join any competition in the Competition page on Kaggle. To do so, search for the competition you want to join in the top bar, select it and click on the \"Join\" button to the right of the name of the competition."},"metadata":{}}]},{"cell_type":"code","source":"# Take one sample\nrow = df.iloc[45]\n\n# Generate Prompt using template\nprompt = template.format(\n    Category=row.Category,\n    Question=row.Question,\n    Answer=\"\"\n)\n\n# Infer\noutput = gemma_lm.generate(prompt, max_length=256)\n\n# Colorize\noutput = colorize_text(output)\n\n# Display in markdown\ndisplay(Markdown(output))","metadata":{"execution":{"iopub.status.busy":"2024-04-01T08:47:11.168757Z","iopub.execute_input":"2024-04-01T08:47:11.169166Z","iopub.status.idle":"2024-04-01T08:47:17.634764Z","shell.execute_reply.started":"2024-04-01T08:47:11.169132Z","shell.execute_reply":"2024-04-01T08:47:17.633789Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='blue'>Category:</font>**\nkaggle-competition-setup\n\n**<font color='red'>Question:</font>**\nHow do Kaggle competitions work?\n\n**<font color='green'>Answer:</font>**\nCompetitions are the heart of Kaggle. They allow users to create a competition from scratch or join an existing one. They can either be hosted on Kaggle or run as a hosted event.\n\nCompetitions can be public, where anyone can see the leaderboard, but only the organizers and other participants in the competition can see the raw data. Alternatively, competitions can be private, where the data is not available to anyone except the organizers and participants in the competition.\n\n## Creating a Competition\n\nTo create a public competition, navigate to https://www.kaggle.com/competition/create in the browser.\n\nTo create a private competition, navigate to https://www.kaggle.com/competition/create-private in the browser.\n\nThe following steps will guide you through the process of creating a new competition.\n\n1. Enter a title (max 128 characters) for your competition\n2. Select a dataset from the dropdown menu (you can also add your own data to a competition)\n3. Select a competition format. There are two formats: “Public” and “Private”.\n4. Click “"},"metadata":{}}]},{"cell_type":"markdown","source":"# Conclusions\n\nWe should improve the model using:\n- More Samples\n- Data Augementation\n- Advanced Prompting\n- Larger Model Gemma 7B\n- Increase `sequence_length`\n- Learning Rate Scheduler","metadata":{}}]}