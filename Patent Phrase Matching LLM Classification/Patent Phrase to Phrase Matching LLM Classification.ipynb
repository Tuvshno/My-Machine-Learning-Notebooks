{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f6d68d-8801-47d3-9301-d6a8b1711cb1",
   "metadata": {},
   "source": [
    "This notebook will be on the U.S. Patent Phrase to Phrase Matching Kaggle Competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce51994-c799-4e09-8661-6772f472ebe1",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "Due to the large database of patents, it is difficult to determine whether a requested patent already exists in the archives. This problem is to solve the problem of trying to find whether the contexts of a patent are semantically similar in order to the office in finding if an invention has been described before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce05001-e1d1-4c73-ac28-774e0ff3edce",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512684ab-48c0-4105-9716-64c970773254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f32b084-e5b0-400c-bad9-1bfbcb04794d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>42d9e032d1cd3242</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>208654ccb9e14fa3</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>756ec035e694722b</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n",
       "...                 ...           ...                     ...     ...    ...\n",
       "36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n",
       "36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n",
       "36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n",
       "36471  756ec035e694722b  wood article         wooden material     B44   0.75\n",
       "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_original = pd.read_csv('train.csv')\n",
    "train_data = train_data_original.copy()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e58742-d6ec-4b86-8db3-fdc6a0af7da1",
   "metadata": {},
   "source": [
    "The data can be described as :\n",
    "- id : unique identifier for a pair of phrases\n",
    "- anchor : the first phrase\n",
    "- target : the second phrase\n",
    "- context : CPC classification which indicates the subject within which the similarity will be scored\n",
    "- score : similarity score\n",
    "\n",
    "The score has additional classifications such as \n",
    "\n",
    "1.0 - Very close match\n",
    "\n",
    "0.75 - Close Synonym\n",
    "\n",
    "0.5 - Synonyms that dont have the same meaning\n",
    "\n",
    "0.25 - Somewhat related\n",
    "\n",
    "0.0 Unrelated\n",
    "\n",
    "There is 0.25 Increment between each classification, which makes this a 5 class classification.\n",
    "\n",
    "Because of that there is an architectural decision of whether we output to 5 neurons with a sigmoid probability or to one neuron and take the nearest interval based on the sigmoid probability of the neuron. I am going to go with the one neuron approach for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa45ea08-d669-4091-bfe7-698874ec8403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          object\n",
      "anchor      object\n",
      "target      object\n",
      "context     object\n",
      "score      float64\n",
      "dtype: object\n",
      "id         False\n",
      "anchor     False\n",
      "target     False\n",
      "context    False\n",
      "score      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check the data for any missing data\n",
    "# Data Summary\n",
    "train_data.shape\n",
    "\n",
    "print(train_data.dtypes)\n",
    "missing_values = train_data.isnull().any()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515c60c-c915-4ab5-9e3e-49bb83c98f91",
   "metadata": {},
   "source": [
    "Luckily there isn't any missing data in any of the sets so we don't have to deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb356cb-aba5-4750-961a-806a0ead859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c750ed-413b-47ed-836a-aff507355803",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c98ef-e8b8-41b9-9cfc-e20c9e6e19e7",
   "metadata": {},
   "source": [
    "My plan of action is goign to be to concatinate each of the features into a single sentence that can be tokenized and put into a Large Language Model and then fine tuned to be a classify the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3551e583-f023-4ffe-9a91-66983f5d6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['input'] = 'Feature1: ' + train_data.anchor + '; Feature2: ' + train_data.target + '; Context: ' + train_data.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc35350-4f46-4533-a460-87caad8b5aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Feature1: abatement; Feature2: abatement of po...\n",
       "1    Feature1: abatement; Feature2: act of abating;...\n",
       "2    Feature1: abatement; Feature2: active catalyst...\n",
       "3    Feature1: abatement; Feature2: eliminating pro...\n",
       "4    Feature1: abatement; Feature2: forest region; ...\n",
       "Name: input, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.input.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8172d18-0da5-4f91-9d52-81ca0d753497",
   "metadata": {},
   "source": [
    "The reason I put the labels and colons is to allow for the LLM to identify the beggining and end of a new label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f41f5-6dfc-48e9-a309-732429f42670",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55c045-2c74-4b4b-a0b5-28dcd873561d",
   "metadata": {},
   "source": [
    "We can't pass text directly into the large language model because it expects numbers as inputs. Therefore we need to do two things:\n",
    "- Tokenize : which is to split each text up into tokens (words/characters/etc)\n",
    "- Numericalize : after getting the tokens, we need to map those tokens into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a056fa-7d2f-4d54-9c42-dea829c147e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of words based on our data using HuggingFace Dataset\n",
    "from datasets import Dataset,DatasetDict\n",
    "\n",
    "ds = Dataset.from_pandas(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d08235a-5155-45fd-97a3-33796fe60104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd5255-5e3d-4dcf-b20e-2684ab012c3c",
   "metadata": {},
   "source": [
    "Because tokenization is model dependent, we have to choose a specific model that we want to work with and then tokenize of data accordingly.\n",
    "\n",
    "I decided that I am going to work with a small model so that training is fast and so we can reiterate quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb037115-8a5b-4a78-8dac-9aa3094b6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'microsoft/deberta-v3-small'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85615c42-f605-4009-bef6-5d4f27b068a6",
   "metadata": {},
   "source": [
    "Using HuggingFace, we can utilize AutoTokenizer so that we automatically utilize the right tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "115a105f-339e-4314-9190-bc7d06160d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_nm, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad64b2b0-84dc-4d1a-a581-fa77389e322d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Hello', ',', '▁this', '▁is', '▁a', '▁token', 'ized', '▁sentence']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"Hello, this is a tokenized sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94b3d9cd-c591-43a3-bbbc-aeadec8a6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize our inputs\n",
    "def tok_func(x): return tokenizer(x[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "518b8024-511e-4daa-978d-956f1c2cd7c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424bd487f27a4448944db8768e00a6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize our dataset in parallel\n",
    "tokenized_dataset = ds.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61570fb6-6d24-4d28-901c-1f02675d1dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Feature1: abatement; Feature2: abatement of pollution; Context: A47',\n",
       " [1,\n",
       "  16855,\n",
       "  435,\n",
       "  294,\n",
       "  47284,\n",
       "  346,\n",
       "  16855,\n",
       "  445,\n",
       "  294,\n",
       "  47284,\n",
       "  265,\n",
       "  6435,\n",
       "  346,\n",
       "  26846,\n",
       "  294,\n",
       "  336,\n",
       "  5753,\n",
       "  2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = tokenized_dataset[0]\n",
    "row['input'], row['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4c61303-08d2-4f19-93d8-0641d9c97e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6891e9a6-395e-4a9d-90cc-2a97e3f24ada",
   "metadata": {},
   "source": [
    "This creates a tokenized dataset where we have the numerical representation of the 'input' inside of 'input_ids'. The numbers come from the vocab of the tokenizer that we used where there is a number for every tokenized word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786f9af7-711c-4f3c-a78c-eb58d1e49544",
   "metadata": {},
   "source": [
    "Now we need to prepare the data for the fine tuning. The model expects the score that to be called 'labels' so we need to change the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af4d86a0-97aa-45f1-9d14-e4fb154d5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.rename_columns({'score':'labels'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd567a-7f02-4f41-9b8f-de9f628720d0",
   "metadata": {},
   "source": [
    "## Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b55eaebc-e0c5-49dd-b97e-1680909b431b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 26625\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9848\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation Set\n",
    "dds = tokenized_dataset.train_test_split(0.27, seed=42)\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c8ce375-23d6-4766-8d90-190724221baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>el display</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id      anchor                         target context\n",
       "count                 36          36                             36      36\n",
       "unique                36          34                             36      29\n",
       "top     4112d61851461f60  el display  inorganic photoconductor drum     G02\n",
       "freq                   1           2                              1       3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv('test.csv')\n",
    "eval_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5231176e-f700-4a27-80cd-85e767393fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffb42c44acb46b3bc6dc604f59bc203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Set\n",
    "eval_df['input'] = 'Feature1: ' + eval_df.anchor + '; Feature2: ' + eval_df.target + '; Context: ' + eval_df.context\n",
    "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1b110e3-cc32-45f5-ad61-65063412f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b6b74-6938-4812-b665-251c79b477b0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdce0345-210e-41e7-94f7-93ddcfed5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fd1dc2f-1171-403b-9743-a0fb1ec106c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "bs = 128\n",
    "epochs = 4\n",
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac9f463a-e048-466a-b3df-5a3c2fcaca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5c66f",
   "metadata": {},
   "source": [
    "Make our model using `Trainer` which combines our data and model together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "781e9825-7a2c-470f-8bbf-2030c3786450",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tuvshno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\tuvshno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=tokenizer, compute_metrics=corr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aeda1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='836' max='836' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [836/836 01:35, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025053</td>\n",
       "      <td>0.807928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>0.826449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.835616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.022188</td>\n",
       "      <td>0.837072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c22415",
   "metadata": {},
   "source": [
    "83% Accuracy is pretty good. Now lets predict our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05f3a373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.61962891],\n",
       "       [ 0.69873047],\n",
       "       [ 0.56054688],\n",
       "       [ 0.34936523],\n",
       "       [-0.01913452],\n",
       "       [ 0.56445312],\n",
       "       [ 0.52001953],\n",
       "       [-0.02534485],\n",
       "       [ 0.33349609],\n",
       "       [ 1.10546875],\n",
       "       [ 0.21020508],\n",
       "       [ 0.25878906],\n",
       "       [ 0.72558594],\n",
       "       [ 0.89306641],\n",
       "       [ 0.77587891],\n",
       "       [ 0.43530273],\n",
       "       [ 0.29077148],\n",
       "       [-0.00983429],\n",
       "       [ 0.65185547],\n",
       "       [ 0.30981445],\n",
       "       [ 0.52001953],\n",
       "       [ 0.2199707 ],\n",
       "       [ 0.08215332],\n",
       "       [ 0.22973633],\n",
       "       [ 0.59082031],\n",
       "       [-0.02456665],\n",
       "       [-0.03564453],\n",
       "       [-0.0496521 ],\n",
       "       [-0.04367065],\n",
       "       [ 0.4753418 ],\n",
       "       [ 0.29443359],\n",
       "       [-0.00561142],\n",
       "       [ 0.68652344],\n",
       "       [ 0.54882812],\n",
       "       [ 0.45458984],\n",
       "       [ 0.23803711]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50f919b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the data so its between 0 and 1\n",
    "preds = np.clip(preds, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116b7fa",
   "metadata": {},
   "source": [
    "Finally lets export our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb1ac5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9f36756de04270b7b832a6ca01cb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': eval_ds['id'],\n",
    "    'score': preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d7639",
   "metadata": {},
   "source": [
    "## Reflections and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb3fcd6",
   "metadata": {},
   "source": [
    "This notebook was using the HuggingFace Transformers library and there was lots of studying to be done on how it should be utilized. Such as the output column of the data should be called 'labels.' It was good experience to utilize the HuggingFace library since its so popular in the field. I also noticed the power of fine tuning the model with a pre-trained model. Even with a small model we started off the training with a 80% accuracy and increased the accuracy from finetuning 3% with only 4 epochs of training. \n",
    "\n",
    "There definitely were some design choices that could be possibly optimized. \n",
    "\n",
    "The input feauture, I arbitrarily chose 'Feature1', 'Feature2' and 'Context'. Possibly there is some optimization there from picking better tokens to differentiate each feature. \n",
    "\n",
    "The validation set could have been chosen better. It used the `train_test_split` function, but that is not a reliable wayn to get a validation set. The function randomly chooses data to take off. Possibly a better way is to not remove unique context features from the training set and only use those, leaving unseen contexts in the validation set. Would this make it be valid?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
